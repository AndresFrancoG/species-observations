{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Add the parameters tag to this cell\n",
    "# kedro_env = 'local'\n",
    "kedro_env = 'test_cloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_project_path = '..//'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from kedro_datasets.pandas import GBQTableDataSet, CSVDataSet\n",
    "from kedro.io import PartitionedDataSet\n",
    "from typing import Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads kedro yml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/18/23 12:25:26] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Config from path <span style=\"color: #008000; text-decoration-color: #008000\">'../conf/test_cloud'</span> will override the following         <a href=\"file:///home/anfef/Codes/2023/Species/species-observations/.venv/lib/python3.10/site-packages/kedro/config/common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/anfef/Codes/2023/Species/species-observations/.venv/lib/python3.10/site-packages/kedro/config/common.py#93\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">93</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         existing top-level config keys: species_data                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/18/23 12:25:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Config from path \u001b[32m'../conf/test_cloud'\u001b[0m will override the following         \u001b]8;id=846121;file:///home/anfef/Codes/2023/Species/species-observations/.venv/lib/python3.10/site-packages/kedro/config/common.py\u001b\\\u001b[2mcommon.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=587290;file:///home/anfef/Codes/2023/Species/species-observations/.venv/lib/python3.10/site-packages/kedro/config/common.py#93\u001b\\\u001b[2m93\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         existing top-level config keys: species_data                              \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kedro.config import ConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "\n",
    "KEDRO_ENV = \"local\"\n",
    "conf_path = str(\"../\" + settings.CONF_SOURCE)\n",
    "conf_loader = ConfigLoader(conf_source=conf_path, env=kedro_env)\n",
    "\n",
    "conf_catalog = conf_loader[\"catalog\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query using bigquery API for query debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bq_query_cat_entry = catalog['bq_test']\n",
    "# project_id = bq_query_cat_entry['project']\n",
    "\n",
    "# Recovers contents of ARRAYS nested inside STRUCTS\n",
    "# sql = \"\"\"SELECT element.array_element\n",
    "#     FROM bigquery-public-data.gbif.occurrences,\n",
    "#     UNNEST(issue.array) AS element\n",
    "#     LIMIT 20\"\"\"\n",
    "\n",
    "# Shows the distinct values of the issue column, which is an ARRAY nested inside a STRUCT\n",
    "# sql = \"\"\"SELECT distinct element.array_element\n",
    "#     FROM bigquery-public-data.gbif.occurrences,\n",
    "#     UNNEST(issue.array) AS element\"\"\"\n",
    "\n",
    "# Counts the number of observations per species and orders it from high to low\n",
    "# sql = \"\"\" SELECT species,\n",
    "#   count(species) as cnt\n",
    "#   FROM bigquery-public-data.gbif.occurrences\n",
    "#   group by species\n",
    "#   order by cnt desc\"\"\"\n",
    "\n",
    "# Counts the number of observations per species and orders it from high to low\n",
    "# sql = \"\"\" SELECT species,\n",
    "#   count(species) as cnt\n",
    "#   FROM bigquery-public-data.gbif.occurrences\n",
    "#   group by species\n",
    "#   order by cnt desc\"\"\"\n",
    "\n",
    "# Gets top 20 rows of all data\n",
    "# sql = \"\"\" SELECT gbifid\n",
    "#     ,datasetkey\n",
    "#     ,occurrenceid\n",
    "#     ,kingdom\n",
    "#     ,phylum\n",
    "#     ,class\n",
    "#     ,`order`\n",
    "#     ,family\n",
    "#     ,genus\n",
    "#     ,species\n",
    "#     ,infraspecificepithet\n",
    "#     ,taxonrank\n",
    "#     ,scientificname\n",
    "#     ,verbatimscientificname\n",
    "#     ,verbatimscientificnameauthorship\n",
    "#     ,countrycode\n",
    "#     ,locality\n",
    "#     ,stateprovince\n",
    "#     ,occurrencestatus\n",
    "#     ,individualcount\n",
    "#     ,publishingorgkey\n",
    "#     ,decimallatitude\n",
    "#     ,decimallongitude\n",
    "#     ,coordinateuncertaintyinmeters\n",
    "#     ,coordinateprecision\n",
    "#     ,elevation\n",
    "#     ,elevationaccuracy\n",
    "#     ,depth\n",
    "#     ,depthaccuracy\n",
    "#     ,eventdate\n",
    "#     ,day\n",
    "#     ,month\n",
    "#     ,year\n",
    "#     ,taxonkey\n",
    "#     ,specieskey\n",
    "#     ,basisofrecord\n",
    "#     ,institutioncode\n",
    "#     ,collectioncode\n",
    "#     ,catalognumber\n",
    "#     ,recordnumber\n",
    "#     ,identifiedby\n",
    "#     ,dateidentified\n",
    "#     ,license\n",
    "#     ,rightsholder\n",
    "#     ,recordedby\n",
    "#     ,typestatus\n",
    "#     ,establishmentmeans\n",
    "#     ,lastinterpreted\n",
    "#     ,mediatype\n",
    "#     ,issue\n",
    "# FROM bigquery-public-data.gbif.occurrences\n",
    "# LIMIT 20 \"\"\"\n",
    "\n",
    "# \n",
    "# sql = \"\"\"SELECT gbifid\n",
    "#     ,kingdom\n",
    "#     ,phylum\n",
    "#     ,class\n",
    "#     ,`order`\n",
    "#     ,family\n",
    "#     ,genus\n",
    "#     ,species\n",
    "#     ,countrycode\n",
    "#     ,occurrencestatus\n",
    "#     ,individualcount\n",
    "#     ,decimallatitude\n",
    "#     ,decimallongitude\n",
    "#     ,eventdate\n",
    "#     ,day\n",
    "#     ,month\n",
    "#     ,year\n",
    "#     ,basisofrecord \n",
    "#     ,element.array_element as issue\n",
    "#     FROM bigquery-public-data.gbif.occurrences\n",
    "#     CROSS JOIN UNNEST(issue.array) AS element\n",
    "#     WHERE species = 'Anas platyrhynchos' AND eventdate > '2020-01-01'\n",
    "#     \"\"\"\n",
    "\n",
    "# data_set = GBQQueryDataSet(sql, project=project_id)\n",
    "# df = data_set.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads csv with data downladed from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_entry = 'species_data'\n",
    "path = relative_project_path + conf_catalog[catalog_entry]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kedro_partitionedDS(path: str, dataset: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Loads as a single dataframe the partitioned data stored in path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the partitioned data\n",
    "    dataset : Dict\n",
    "        Type of data to search for and load options (dataset option in kedro's catalog of type PartitionedDataSet)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        joined dataset\n",
    "    \"\"\"\n",
    "    data_set = PartitionedDataSet(\n",
    "        path=path,\n",
    "        dataset=dataset,\n",
    "    )\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    loaded = data_set.load()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for partition_id, partition_load_func in loaded.items():\n",
    "        partition_data = partition_load_func()\n",
    "        df = pd.concat(\n",
    "            [df, partition_data], ignore_index=True, sort=True\n",
    "        )\n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kedro_env == 'local':\n",
    "    dataset = conf_catalog[catalog_entry]['dataset']\n",
    "    df = load_kedro_partitionedDS(path, dataset)\n",
    "elif kedro_env == 'test_cloud':\n",
    "    data_set = CSVDataSet(filepath=path)\n",
    "    df = data_set.load()\n",
    "else:\n",
    "    raise ValueError('Undefined kedro environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        1000 non-null   int64  \n",
      " 1   basisofrecord     1000 non-null   object \n",
      " 2   class             1000 non-null   object \n",
      " 3   countrycode       1000 non-null   object \n",
      " 4   day               1000 non-null   float64\n",
      " 5   decimallatitude   1000 non-null   float64\n",
      " 6   decimallongitude  1000 non-null   float64\n",
      " 7   eventdate         1000 non-null   object \n",
      " 8   family            1000 non-null   object \n",
      " 9   gbifid            1000 non-null   int64  \n",
      " 10  genus             1000 non-null   object \n",
      " 11  individualcount   903 non-null    float64\n",
      " 12  issue             1000 non-null   object \n",
      " 13  kingdom           1000 non-null   object \n",
      " 14  month             1000 non-null   float64\n",
      " 15  occurrencestatus  1000 non-null   object \n",
      " 16  order             1000 non-null   object \n",
      " 17  phylum            1000 non-null   object \n",
      " 18  species           1000 non-null   object \n",
      " 19  year              1000 non-null   int64  \n",
      "dtypes: float64(5), int64(3), object(12)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates sample data for automatic testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "# test_catalog_entry = 'species_data'\n",
    "# test_path = '..//' + conf_catalog[test_catalog_entry]['path']\n",
    "\n",
    "# sample_index = combine_all.species.sample(1000).index\n",
    "# sample_df = combine_all.loc[sample_index]\n",
    "# sample_df.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "species",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
